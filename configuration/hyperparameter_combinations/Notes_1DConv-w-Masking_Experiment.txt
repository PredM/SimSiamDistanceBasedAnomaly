
# Set the right Configuration: cnn2d_withAddInput_cnn1DMaskingExperiment.json, set featureWeightedSim: False, set strictMasking: False,
# Replace class CNN2dWithAddInput with the following
# Replace SSN as the following (because only 1 output is provided by the network instead of multiple)
class CNN2dWithAddInput(NN):

    def __init__(self, hyperparameters, input_shape):
        super().__init__(hyperparameters, input_shape)
        self.output_shape = None

    def create_model(self):

        print('Creating CNN with 2d kernel encoder with a sensor data input shape: ', self.input_shape[0],
              " and additional input shape: ", self.input_shape[1], "and adjacency matrix: ", self.input_shape[2],
              "and static attribute features with shape: ", self.input_shape[3])

        # Input definition of sensor data and masking
        sensor_data_input = tf.keras.Input(shape=(self.input_shape[0][0], self.input_shape[0][1]),
                                           name="SensorDataInput")
        case_dependent_vector_input_i = tf.keras.Input(self.input_shape[1], name="MaskingVectorInput")
        masking_vec_len = self.input_shape[1]
        adj_matrix_input = tf.keras.layers.Input(shape=(self.input_shape[2],), name="AdjacencyMatrix")
        static_attribute_features_input = tf.keras.layers.Input(shape=self.input_shape[3], name="StaticAttributeFeatures")

        # Splitting masking vectors in normal and strict
        if self.hyper.use_additional_strict_masking == 'True':
            print("Masking: normal + strict")
            half = int(masking_vec_len / 2)
            case_dependent_vector_input = tf.keras.layers.Lambda(lambda x: x[:, :half], name="SplitMaskVec_Context")(
                case_dependent_vector_input_i)
            case_dependent_vector_input_strict = tf.keras.layers.Lambda(lambda x: x[:, half:masking_vec_len],
                                                                        name="SplitMaskVec_Strict")(
                case_dependent_vector_input_i)
        else:
            print("Masking: normal")
            case_dependent_vector_input = case_dependent_vector_input_i
            case_dependent_vector_input_strict = case_dependent_vector_input_i

        layers = self.hyper.cnn2d_layers

        print("learnFeatureWeights: False Feature weights are similar to masking vector")
        # case_dependent_vector_input_o = tf.keras.layers.GaussianNoise(0.3)(case_dependent_vector_input_strict)
        # case_dependent_vector_input_o = tf.multiply(case_dependent_vector_input_o, case_dependent_vector_input_strict)
        case_dependent_vector_input_o = case_dependent_vector_input_strict

        self.hyper.abcnn1 = None

        if len(layers) < 1:
            print('CNN encoder with less than one layer for 2d kernels is not possible')
            sys.exit(1)

        layer_properties = list(zip(self.hyper.cnn2d_layers, self.hyper.cnn2d_kernel_length, self.hyper.cnn2d_strides, self.hyper.cnn2d_dilation_rate))
        # Creating 1d-CNN encoder
        conv_layer1 = tf.keras.layers.Conv1D(filters=256, padding='VALID', kernel_size=5,
                                            strides=2, input_shape=self.input_shape)


        conv_layer2 = tf.keras.layers.Conv1D(filters=64, padding='VALID', kernel_size=5,
                                        strides=2)
        conv_layer3 = tf.keras.layers.Conv1D(filters=32, padding='VALID', kernel_size=3,
                                             strides=1)

        x = tf.keras.layers.Multiply()([sensor_data_input, case_dependent_vector_input])
        x = conv_layer1(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.ReLU()(x)
        x = conv_layer2(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.ReLU()(x)
        x = conv_layer3(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.ReLU()(x)
        x = tf.keras.layers.Dropout(rate=self.hyper.dropout_rate)(x)
        x = tf.keras.layers.Flatten()(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu)(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu)(x)
        x = tf.keras.layers.Reshape((64, 1))(x)
        self.model = tf.keras.Model(
            inputs=[sensor_data_input, case_dependent_vector_input_i, adj_matrix_input,
                    static_attribute_features_input],
            outputs=[x])

    def kl_divergence_regularizer(self, inputs):
        means = tf.keras.backend.mean(inputs, axis=0)
        return 0.1 * (tf.keras.losses.kullback_leibler_divergence(0.5, means)
                       + tf.keras.losses.kullback_leibler_divergence(1 - 0.5, 1 - means))

    def get_output_shape(self):
        # output shape only from first output x
        return self.model.output_shape[0]
        # raise NotImplementedError('Must be added in order for ffnn version to work with this encoder')

### SNN.py Replacement:
            # Output of encoder are encoded time series and additional things e.g., weights vectors
            #a = context_vectors[0][2 * pair_index, :, :]
            #b = context_vectors[0][2 * pair_index + 1, :, :]
            a = context_vectors[2 * pair_index, :, :]
            b = context_vectors[2 * pair_index + 1, :, :]
            '''
            if self.config.useFeatureWeightedSimilarity:
                a_weights = context_vectors[1][2 * pair_index, :]
                b_weights = context_vectors[1][2 * pair_index + 1, :]
            if self.encoder.hyper.useAddContextForSim == 'True':
                a_context = context_vectors[2][2 * pair_index, :]
                b_context = context_vectors[2][2 * pair_index + 1, :]
            if self.encoder.hyper.useAddContextForSim_LearnOrFixWeightVale == 'True':
                w = context_vectors[3][2 * pair_index, :]
                # debug output:
                # tf.print("context_vectors[3][2 * pair_index, :]", context_vectors[4][2 * pair_index, :])
            '''

                beta_0 = tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu,
                                               name="Beta-Context" + str(64) + "U")(case_dependent_vector_input)
                beta_1 = tf.keras.layers.Dense(units=61, activation=tf.keras.activations.relu,
                                               name="BetaContext" + str(61) + "U")(beta_0)
                gamma_0 = tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu,
                                                name="GammaContext" + str(64) + "U")(case_dependent_vector_input)
                gamma_1 = tf.keras.layers.Dense(units=61, activation=tf.keras.activations.relu,
                                                name="GammaContext" + str(61) + "U")(gamma_0)
                beta_1 = tf.keras.layers.Multiply()([beta_1, case_dependent_vector_input])
                gamma_1 = tf.keras.layers.Multiply()([gamma_1, case_dependent_vector_input])
                tns = tf.concat([gamma_1, beta_1], axis=1)
                x = FiLM()([x, tns])