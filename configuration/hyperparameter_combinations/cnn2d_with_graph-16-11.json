{
  "notes": "based on 26-10, but changed grah conv and ap form 64 to 96, had to decrease batch size",
  "encoder_variant": "graphcnn2d",
  "batch_size": 48,
  "epochs": 400000,
  "epochs_current": 0,
  "learning_rate": 0.001,
  "gradient_cap": -1,
  "dropout_rate": 0.05,
  "ffnn_layers": [
    64,
    16
  ],
  "cnn_layers": [
  ],
  "cnn_kernel_length": [
  ],
  "cnn_strides": [
  ],
  "graph_conv_channels": [
    96
  ],
  "global_attention_pool_channels": [
    96
  ],
  "cnn2d_layers": [
    128,
    64,
    1
  ],
  "cnn2d_kernel_length": [
    [
      5,
      1
    ],
    [
      5,
      1
    ],
    [
      1,
      1
    ]
  ],
  "cnn2d_strides": [
    [
      2,
      1
    ],
    [
      1,
      1
    ],
    [
      1,
      1
    ]
  ]
}