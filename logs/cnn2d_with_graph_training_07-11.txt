
Dataset loaded:
Shape of training set (example, time, channels): (25550, 1000, 61)
Shape of test set (example, time, channels): (3389, 1000, 61)
Num of classes in train and test together: 29

Creating standard SNN with simple similarity measure:  SimpleSimilarityMeasure.ABS_MEAN
Creating CNN with 2d kernel encoder with an input shape:  (1000, 61)
Attention: No 1d conv layer on top of 2d conv is used!

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input0 (InputLayer)             [(None, 1000, 61, 1) 0                                            
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1000, 61)     0           Input0[0][0]                     
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1000, 61)     3782        reshape[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_ExpandDims (TensorF [(None, 1000, 61, 1) 0           conv1d[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_concat (TensorFlowO [(None, 1000, 61, 2) 0           Input0[0][0]                     
                                                                 tf_op_layer_ExpandDims[0][0]     
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 498, 61, 128) 1408        tf_op_layer_concat[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 498, 61, 128) 512         conv2d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 498, 61, 128) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 494, 61, 64)  41024       re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 494, 61, 64)  256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 494, 61, 64)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 494, 61, 1)   65          re_lu_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 494, 61, 1)   4           conv2d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 494, 61, 1)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 494, 61)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 494, 61)      0           reshape_1[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_Transpose (TensorFl [(None, 61, 494)]    0           dropout[0][0]                    
__________________________________________________________________________________________________
input_1 (InputLayer)            [(None, 61)]         0                                            
__________________________________________________________________________________________________
graph_conv (GraphConv)          (None, 61, 32)       15840       tf_op_layer_Transpose[0][0]      
                                                                 input_1[0][0]                    
__________________________________________________________________________________________________
global_attention_pool (GlobalAt (None, 32)           2112        graph_conv[0][0]                 
==================================================================================================
Total params: 65,003
Trainable params: 64,617
Non-trainable params: 386
__________________________________________________________________________________________________

Training:
Timestamp: 07.11 17:59:29 (4.06 Seconds since last output) - Epoch: 0 - Loss: 4.59168 - Name: 
Timestamp: 07.11 18:00:08 (38.23 Seconds since last output) - Epoch: 100 - Loss: 0.50083 - Name: temp_snn_model_11-07_18-00-08_epoch-100/
Timestamp: 07.11 18:00:46 (38.08 Seconds since last output) - Epoch: 200 - Loss: 0.38620 - Name: temp_snn_model_11-07_18-00-46_epoch-200/
Timestamp: 07.11 18:01:24 (38.06 Seconds since last output) - Epoch: 300 - Loss: 0.33098 - Name: temp_snn_model_11-07_18-01-24_epoch-300/
Timestamp: 07.11 18:02:02 (38.24 Seconds since last output) - Epoch: 400 - Loss: 0.34534 - Name: temp_snn_model_11-07_18-02-02_epoch-400/
Timestamp: 07.11 18:02:40 (37.73 Seconds since last output) - Epoch: 500 - Loss: 0.30901 - Name: temp_snn_model_11-07_18-02-40_epoch-500/
Early stopping: Training stopped at epoch  569  because loss did not decrease since  300 epochs.
