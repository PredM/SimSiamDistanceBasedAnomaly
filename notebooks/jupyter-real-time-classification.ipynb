{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Jupyter notebook for executing the real time classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparations:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "e:\\dokumente\\python\\python-tf-2\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.21.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from data_processing.RealTimeClassification import *\n",
    "\n",
    "config = Configuration()\n",
    "\n",
    "# suppress debugging messages of tensorflow\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# load the scalers of the training data for the normalisation\n",
    "scalers = load_scalers(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change config if needed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Configured Server: localhost:9092\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Configured Server:', config.get_connection())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create consumers for each topic:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Creating consumers ...\n\n",
      "Configured kafka server is not available. Please check the connection or change the configuration.\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ],
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error"
    },
    {
     "name": "stderr",
     "text": [
      "e:\\dokumente\\python\\python-tf-2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "consumers = []\n",
    "limiting_consumer = None\n",
    "\n",
    "print('Creating consumers ...\\n')\n",
    "\n",
    "# if using the fabric simulation start at the start of the topics\n",
    "# for live classification start at newest messages possible\n",
    "offset = 'earliest' if config.testing_using_fabric_sim else 'latest'\n",
    "\n",
    "try:\n",
    "    # create consumers for all topics\n",
    "    for topic in config.topic_list:\n",
    "        c = KafkaConsumer(topic, bootstrap_servers=config.get_connection(),\n",
    "                          value_deserializer=lambda m: json.loads(m.decode('utf-8')),\n",
    "                          auto_offset_reset=offset)\n",
    "\n",
    "        # based on the topic select one of the consumers for time interval determination\n",
    "        if topic == config.limiting_topic:\n",
    "            limiting_consumer = c\n",
    "\n",
    "        consumers.append(c)\n",
    "except errors.NoBrokersAvailable:\n",
    "    print('Configured kafka server is not available. Please check the connection or change the configuration.')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create and start a classifier thread that handles the classification of processed examples:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\\nCreating classifier ...')\n",
    "print('\\nUsed model file:')\n",
    "print(config.directory_model_to_use, '\\n')\n",
    "\n",
    "print('The classifier will use k=' + str(config.k_of_knn) + ' for the k-NN algorithm')\n",
    "print('The mean similarity output is calculated on the basis of the k most similar cases')\n",
    "print('The time span is the time between the end timestamp of the')\n",
    "print('interval and the current time right before the output.')\n",
    "print('The total time is the time needed for the completely processing the example,')\n",
    "print('including the time in the queue.\\n')\n",
    "classifier = Classifier(config)\n",
    "classifier.start()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start the classification process as soon as data is available:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Waiting for data to classify ...\\n')\n",
    "try:\n",
    "\n",
    "    # classify as until interrupted\n",
    "    while 1:\n",
    "        start_time = time.perf_counter()\n",
    "        # read data for a single example from kafka, results contains lists of single messages\n",
    "        results = read_single_example(consumers, limiting_consumer, config)\n",
    "\n",
    "        # combine into a single dataframe\n",
    "        df = list_to_dataframe(results, config)\n",
    "\n",
    "        # transform dataframe into a array that can be used as neural network input\n",
    "        example = df.to_numpy()\n",
    "\n",
    "        # normalize the data of the example\n",
    "        example = normalise_dataframe(example, scalers)\n",
    "\n",
    "        # create a queue element containing\n",
    "        element = (example, df.index[0], df.index[-1], start_time)\n",
    "\n",
    "        # add element to the queue of examples to classify\n",
    "        classifier.examples_to_classify.put(element)\n",
    "\n",
    "        # reset all consumer offsets by two messages to reduce the time intervals that are left out\n",
    "        for i in range(len(consumers)):\n",
    "            partition = TopicPartition(config.topic_list[i], 0)\n",
    "            last_offset = consumers[i].position(partition)\n",
    "            new_offset = last_offset - 2 if last_offset - 2 >= 0 else 0\n",
    "            consumers[i].seek(partition, new_offset)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # interrupt the classifier thread\n",
    "    print('Exiting ...\\n')\n",
    "    classifier.stop = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}