
Dataset loaded:
Shape of training set (example, time, channels): (25550, 1000, 61)
Shape of test set (example, time, channels): (3389, 1000, 61)
Num of classes in train and test together: 29

Creating standard SNN with simple similarity measure:  abs_mean
Creating CNN with 2d kernel encoder with an input shape:  (1000, 61)
Attention: No 1d conv layer on top of 2d conv is used!

Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input0 (InputLayer)             [(None, 1000, 61, 1) 0                                            
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1000, 61)     0           Input0[0][0]                     
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1000, 61)     3782        reshape[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_ExpandDims (TensorF [(None, 1000, 61, 1) 0           conv1d[0][0]                     
__________________________________________________________________________________________________
tf_op_layer_concat (TensorFlowO [(None, 1000, 61, 2) 0           Input0[0][0]                     
                                                                 tf_op_layer_ExpandDims[0][0]     
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 498, 61, 128) 1408        tf_op_layer_concat[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 498, 61, 128) 512         conv2d[0][0]                     
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 498, 61, 128) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 494, 61, 64)  41024       re_lu[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 494, 61, 64)  256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 494, 61, 64)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 494, 61, 1)   65          re_lu_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 494, 61, 1)   4           conv2d_2[0][0]                   
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 494, 61, 1)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 494, 61)      0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 494, 61)      0           reshape_1[0][0]                  
__________________________________________________________________________________________________
tf_op_layer_Transpose (TensorFl [(None, 61, 494)]    0           dropout[0][0]                    
__________________________________________________________________________________________________
input_1 (InputLayer)            [(None, 61)]         0                                            
__________________________________________________________________________________________________
graph_conv (GraphConv)          (None, 61, 64)       31680       tf_op_layer_Transpose[0][0]      
                                                                 input_1[0][0]                    
__________________________________________________________________________________________________
global_attention_pool (GlobalAt (None, 64)           8320        graph_conv[0][0]                 
==================================================================================================
Total params: 87,051
Trainable params: 86,665
Non-trainable params: 386
__________________________________________________________________________________________________

Training:
Timestamp: 26.10 15:02:58 (4.15 Seconds since last output) - Epoch: 0 - Loss: 6.49443 - Name: 
Timestamp: 26.10 15:03:36 (37.91 Seconds since last output) - Epoch: 100 - Loss: 0.46797 - Name: temp_snn_model_10-26_15-03-36_epoch-100/
Timestamp: 26.10 15:04:14 (38.13 Seconds since last output) - Epoch: 200 - Loss: 0.33475 - Name: temp_snn_model_10-26_15-04-14_epoch-200/
Timestamp: 26.10 15:04:52 (38.06 Seconds since last output) - Epoch: 300 - Loss: 0.31319 - Name: temp_snn_model_10-26_15-04-52_epoch-300/
Timestamp: 26.10 15:05:30 (38.16 Seconds since last output) - Epoch: 400 - Loss: 0.40091 - Name: temp_snn_model_10-26_15-05-30_epoch-400/
Timestamp: 26.10 15:06:08 (38.08 Seconds since last output) - Epoch: 500 - Loss: 0.27543 - Name: temp_snn_model_10-26_15-06-08_epoch-500/
Timestamp: 26.10 15:06:46 (37.97 Seconds since last output) - Epoch: 600 - Loss: 0.28988 - Name: temp_snn_model_10-26_15-06-46_epoch-600/
Timestamp: 26.10 15:07:25 (38.39 Seconds since last output) - Epoch: 700 - Loss: 0.29309 - Name: temp_snn_model_10-26_15-07-25_epoch-700/
Timestamp: 26.10 15:08:03 (38.11 Seconds since last output) - Epoch: 800 - Loss: 0.30382 - Name: temp_snn_model_10-26_15-08-03_epoch-800/
Timestamp: 26.10 15:08:41 (38.19 Seconds since last output) - Epoch: 900 - Loss: 0.22684 - Name: temp_snn_model_10-26_15-08-41_epoch-900/
Timestamp: 26.10 15:09:19 (38.03 Seconds since last output) - Epoch: 1000 - Loss: 0.25260 - Name: temp_snn_model_10-26_15-09-19_epoch-1000/
Early stopping: Training stopped at epoch  1090  because loss did not decrease since  300 epochs.
